# logger options
image_save_iter: 2000         # How often do you want to save output images during training
#image_display_iter: 100       # How often do you want to display output images during training
h_scale: 1                    # scale the w/h ratio when save images
w_scale: 1                    # scale the w/h ratio when save images
display_size: 10               # How many images do you want to display each row
snapshot_save_iter: 20000     # How often do you want to save trained models
log_iter: 10                  # How often do you want to log the training stats

# optimization options
max_iter: 200000              # maximum number of training iterations, qss
batch_size: 16                # batch size, qss
weight_decay: 0.0001          # weight decay
beta1: 0.5                    # Adam parameter, qss 0.5 or 0.0
beta2: 0.999                  # Adam parameter
init: kaiming                 # initialization [gaussian/kaiming/xavier/orthogonal]
lr: 0.0001                    # initial learning rate, qss 0.0001/0.0002
lr_policy: step               # learning rate scheduler
step_size: 50000             # how often to decay learning rate, qss
gamma: 0.5                    # how much to decay learning rate
gan_w: 1                      # weight of adversarial loss, qss
recon_x_w: 10                 # weight of image reconstruction loss, qss
recon_s_w: 1                  # weight of style reconstruction loss, qss
recon_c_w: 1                  # weight of content reconstruction loss, qss
disent_cls_w: 1
disent_ent_w: 1
tv_w: 0                       # weight of total variation loss, qss [<10?]

# model options
gen:
  dim: 32                     # number of filters in the bottommost layer
  mlp_dim: 128                # number of filters in MLP
  style_dim: 8                # length of style code, qss
  activ: relu                 # activation function [relu/lrelu/prelu/selu/tanh]
  n_downsample: 2             # number of downsampling layers in content encoder, qss
  n_res: 3                    # number of residual blocks in content encoder/decoder
  pad_type: reflect           # padding type [zero/reflect]
  tree: [2, 3, 2, 1, 2]       # qss

dis:
  dim: 32                     # number of filters in the bottommost layer
  norm: none                  # normalization layer [none/bn/in/ln], qss snXX ?
  activ: lrelu                # activation function [relu/lrelu/prelu/selu/tanh]
  n_layer: 4                  # number of layers in D, qss
  gan_type: lsgan             # GAN loss [lsgan/nsgan/wgan-gp], qss
  num_scales: 1               # number of scales, qss
  pad_type: reflect           # padding type [zero/reflect]
  tree: [2, 3, 2, 1, 2]

# data options
input_dim: 1                                # number of image channels [1/3]
num_workers: 5                              # number of data loading threads
new_size: 28                               # first resize the shortest image side to this size, qss
crop_image_height: 28                      # random crop image of this height, qss
crop_image_width: 28                       # random crop image of this width, qss

model_name: fmnist                                                                # model name of each try, qss
data_folder: /home/qiaoshishi/datasets/Fashion_Mnist/                             # data root folder, qss
train_list_file: train.txt                                                         # train txt file name, qss
test_list_file: test.txt                                                           # test txt file name , qss
filter_labels: [0, 2, 4, 1, 3]
